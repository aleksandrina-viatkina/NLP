{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDq139uDxcbr"
   },
   "source": [
    "# Домашнее задание к вебинару 9\n",
    "\n",
    "Задание: обучить генератор текстов\n",
    "Обучаем генератор символов (будет предсказывать следующий символ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DGHeo6gkxa51"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2-O6xtX1rLj",
    "outputId": "cef3a6f9-79aa-47b0-a1c6-8a02b39c858e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CmR_wHmm1tU9"
   },
   "outputs": [],
   "source": [
    "path_to_file = '/content/evgenyi_onegin.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IBtQ5nLN1tS5",
    "outputId": "8f24b65c-52f9-40ed-8e5c-ef3bcf37b0ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 286984 characters\n"
     ]
    }
   ],
   "source": [
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W1BYW9xK1tQj",
    "outputId": "c412160f-0f52-4494-c911-a73475ae5b4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Александр Сергеевич Пушкин\n",
      "\n",
      "                                Евгений Онегин\n",
      "                                Роман в стихах\n",
      "\n",
      "                        Не мысля гордый свет забавить,\n",
      "                        Вниманье дружбы возлюбя,\n",
      "                        Хотел бы я тебе представить\n",
      "                        Залог достойнее тебя,\n",
      "                        Достойнее души прекрасной,\n",
      "                        Святой исполненной мечты,\n",
      "                        Поэзии живой и ясной,\n",
      "                        Высо\n"
     ]
    }
   ],
   "source": [
    "# Выведем фрагмент текста\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TxrsULVi1tOP",
    "outputId": "177d1f12-5b50-43c7-e36f-611644bd17e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 unique characters\n"
     ]
    }
   ],
   "source": [
    "# Вывелем все уникальные символы (буквы+символы) в тексте\n",
    "vocab = sorted(set(text))\n",
    "print('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J5WqJZou1tL2",
    "outputId": "d7fa5416-4bb7-46a5-df40-0a47196e0762"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rl5ojqWa1tJy"
   },
   "outputs": [],
   "source": [
    "# Задаем отображения из множества уникальных букв в множество индексов\n",
    "char2idx = {u:i for i, u in enumerate(vocab)} # словарь {индекс: символ (буква или символ)}\n",
    "\n",
    "idx2char = np.array(vocab) # array из символов словаря (можно по индексу извлекать букву)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUdSQdlJ1tHe",
    "outputId": "552fd071-4781-4e97-b2c0-923f626aa508"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2',\n",
       "       '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C',\n",
       "       'D', 'E', 'F', 'G', 'H', 'I', 'L', 'M', 'N', 'O', 'P', 'Q', 'R',\n",
       "       'S', 'T', 'V', 'W', 'X', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g',\n",
       "       'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u',\n",
       "       'v', 'w', 'y', 'z', '{', '}', 'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж',\n",
       "       'З', 'И', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'У', 'Ф',\n",
       "       'Х', 'Ц', 'Ч', 'Ш', 'Ь', 'Э', 'Ю', 'Я', 'а', 'б', 'в', 'г', 'д',\n",
       "       'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с',\n",
       "       'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю',\n",
       "       'я'], dtype='<U1')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "IUMFu5yb7Gv9"
   },
   "outputs": [],
   "source": [
    "# Теперь переводим все символы текста в индексы\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KP4YfojU7NWf",
    "outputId": "65add2ae-d163-4a92-b760-782c24b59fe1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 71, 110, 104, ..., 104, 121,   0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mqr2dZ1SBsb9",
    "outputId": "2827c7b2-7611-4948-b4ff-34e649e9533e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Александр Сергеевич Пушкин\n",
      "\n",
      "                                Евгений Онегин\n",
      "                                Роман в стихах\n",
      "\n",
      "                        Не мысля гордый свет забавить,\n",
      "                        Вниманье дружбы возлюбя,\n",
      "                        Хотел бы я тебе представить\n",
      "                        Залог достойнее тебя,\n",
      "                        Достойнее души прекрасной,\n",
      "                        Святой исполненной мечты,\n",
      "                        Поэзии живой и ясной,\n",
      "                        Высо\n",
      "[ 71 110 104 109 116  99 112 103 115   1  87 104 115 102 104 104 101 107\n",
      " 122   1  85 118 123 109 107 112   0   0   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1  76 101 102 104 112 107 108   1  84 112 104 102\n",
      " 107 112   0   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1  86\n",
      " 113 111  99 112   1 101   1 116 117 107 120  99 120   0   0   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1  83 104   1 111 126 116 110 130   1 102 113 115 103 126 108\n",
      "   1 116 101 104 117   1 106  99 100  99 101 107 117 127   7   0   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1  73 112 107 111  99 112 127 104   1 103 115 118 105 100\n",
      " 126   1 101 113 106 110 129 100 130   7   0   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1  91\n",
      " 113 117 104 110   1 100 126   1 130   1 117 104 100 104   1 114 115 104\n",
      " 103 116 117  99 101 107 117 127   0   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1  78  99 110\n",
      " 113 102   1 103 113 116 117 113 108 112 104 104   1 117 104 100 130   7\n",
      "   0   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1  75 113 116 117 113 108 112 104 104   1 103\n",
      " 118 123 107   1 114 115 104 109 115  99 116 112 113 108   7   0   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1  87 101 130 117 113 108   1 107 116 114 113 110 112 104\n",
      " 112 112 113 108   1 111 104 122 117 126   7   0   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "  85 113 128 106 107 107   1 105 107 101 113 108   1 107   1 130 116 112\n",
      " 113 108   7   0   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1  73 126 116 113]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text[:500]), print(text_as_int[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jD9O5oKaEA0m"
   },
   "source": [
    "### Подготовка данных к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQTJbGozBsZn",
    "outputId": "d08fba70-432c-4a12-c777-eefc02381c33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "А 286984\n",
      "л 286984\n",
      "е 286984\n",
      "к 286984\n",
      "с 286984\n"
     ]
    }
   ],
   "source": [
    "# Максимальная длина предложения (максимальное количество слов в батче) для входных данных (в буквах)\n",
    "seq_length = 100\n",
    "\n",
    "# Количество эпох\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# создаем датасет из данных\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()], len(char_dataset)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "33zahMcbBsXV"
   },
   "outputs": [],
   "source": [
    "# Создаем последовательность батчей (размер батча = 101)\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TzOwSNfaE7GT",
    "outputId": "89f38a0f-0200-4270-da58-f47d6a54168d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Александр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                          '\n",
      "'      Роман в стихах\\n\\n                        Не мысля гордый свет забавить,\\n                        '\n",
      "'Вниманье дружбы возлюбя,\\n                        Хотел бы я тебе представить\\n                        '\n",
      "'Залог достойнее тебя,\\n                        Достойнее души прекрасной,\\n                        Свят'\n",
      "'ой исполненной мечты,\\n                        Поэзии живой и ясной,\\n                        Высоких д'\n"
     ]
    }
   ],
   "source": [
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "prpupE8ZN66_"
   },
   "outputs": [],
   "source": [
    "# Разбиваем каждый батч на признаки и целевую переменную (следующую букву)\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "#применяем функцию split_input_target ко всем батчам\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gO9Z2RReN692",
    "outputId": "f7e636a7-9bb7-4265-b622-9251947bd8a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество батчей: 2841\n",
      "Данные: [ 71 110 104 109 116  99 112 103 115   1  87 104 115 102 104 104 101 107\n",
      " 122   1  85 118 123 109 107 112   0   0   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1  76 101 102 104 112 107 108   1  84 112 104 102\n",
      " 107 112   0   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1]\n",
      "Целевая переменная: [110 104 109 116  99 112 103 115   1  87 104 115 102 104 104 101 107 122\n",
      "   1  85 118 123 109 107 112   0   0   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1  76 101 102 104 112 107 108   1  84 112 104 102 107\n",
      " 112   0   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1]\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset:\n",
    "    print(f'Количество батчей: {len(dataset)}')\n",
    "    print(f'Данные: {input_example}')\n",
    "    print(f'Целевая переменная: {target_example}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XpKEEp3UQJRD",
    "outputId": "44fa1471-61e4-454e-de10-b487ff5499f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'Александр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                         '\n",
      "Target data: 'лександр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                          '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vaz-wkhTRx7n"
   },
   "source": [
    "### Построение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "jFj0g7Z2QJNv"
   },
   "outputs": [],
   "source": [
    "# размер батча\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# размер буфера для перемешивания данных\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "# перемешивание разделенных данных\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z7b-jnH02Dju",
    "outputId": "537b756b-be8b-4037-8fcc-d46a2cb89d0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n",
      "(64, 100) (64, 100)\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset:\n",
    "    print(input_example.shape, target_example.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "vyl2qomVQJKo"
   },
   "outputs": [],
   "source": [
    "# Длина словаря\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Длина выходного эмбеддинга\n",
    "embedding_dim = 256\n",
    "\n",
    "# Количество скрытых состояний в RNN слое \n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "xR8-yQM-Srjt"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "                                 \n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "         tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        \n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "                                   \n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "P0S4yAlYN7AY"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gvWFtxhXrBla",
    "outputId": "cca120b8-ff94-4aad-b920-968cf0e9740c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (64, None, 256)           33536     \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (64, None, 131)           134275    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,592,899\n",
      "Trainable params: 30,592,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzN7K11Osvcx"
   },
   "source": [
    "**Сделаем предсказание без обучения модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DTzYZ1PKVjEU",
    "outputId": "d8ee8a05-bc1c-45a5-e9eb-5c7173ef5e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 131)  # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape,\" # (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54W4AUFkzCQp",
    "outputId": "ad352b17-4074-4e7c-dbda-6cd7ff138eb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1IGh01zlVjBi",
    "outputId": "6e9ed02d-0011-4003-a703-fa5d141b44c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 131), dtype=float32, numpy=\n",
       "array([[-1.81417954e-06,  4.00193403e-06,  3.88547869e-06, ...,\n",
       "        -1.64471712e-05,  1.55858397e-05, -1.20994455e-05],\n",
       "       [-2.22608378e-05,  1.18116441e-06, -2.58475138e-05, ...,\n",
       "        -2.25488366e-05,  5.01978466e-05, -3.32598174e-05],\n",
       "       [-5.70883458e-05, -3.95189818e-05, -9.98164469e-05, ...,\n",
       "        -4.09461973e-06,  9.66930165e-05, -5.00300594e-05],\n",
       "       ...,\n",
       "       [-3.15367640e-03, -1.52308925e-03, -6.85384206e-04, ...,\n",
       "         1.61391473e-03, -1.53077301e-03, -9.19225393e-04],\n",
       "       [-3.02344514e-03, -1.38021854e-03, -7.05452985e-04, ...,\n",
       "         1.56130770e-03, -1.39190443e-03, -8.37130705e-04],\n",
       "       [-2.87503889e-03, -1.32162811e-03, -8.16532178e-04, ...,\n",
       "         1.46284408e-03, -1.28053129e-03, -7.66042853e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvpyXmyZBsU1",
    "outputId": "c495ce16-c9c5-465e-f332-25ba78afc50f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15,   4,  68,  61,  70,  43,   6,  54,  64, 126, 114,  94,  31,\n",
       "        96, 104,  68, 119,  68,  68, 102,  39,  20,  93,  94,  20,   0,\n",
       "       128,   6,   2,  87, 114,  91,  91,  36,  83,   3,  47, 101,  54,\n",
       "        10,  11,  99,  19, 111,  59,   6,  11,  41,   0,  56,  11,  80,\n",
       "       126,  55,  82,  11,  74,  27, 122,  25,  80,  18, 117,   4, 126,\n",
       "        23,  18,  25, 104,  63,  16, 101,   1,  93,   1,  91, 109,   7,\n",
       "       111,  75, 120,  24,  12, 124, 111,  15,  84,  52,  24,  18,  91,\n",
       "        18, 125, 107, 126,  65,  24,   3,  89,   4])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сэмплируем предсказание \n",
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1) #количество независимых выборок 1\n",
    "\n",
    "#убираем лишнюю размерность (список индексов)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G7F0tNQysQDE",
    "outputId": "9b24eef6-0116-4346-b316-71b017c8e5ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'ц,\\n                        Давал три бала ежегодно\\n                        И промотался наконец.\\n   '\n",
      "\n",
      "Next Char Predictions: \n",
      " '5\\'zr}X)kuыпШIЭеzфzzгS:ЧШ:\\nэ)!СпХХPН\"cвk01а9мp)1V\\nm1КыlМ1ГEчCК8т\\'ыA8Cеt6в Ч Хк,мДхB2щм5ОhB8Х8ъиыvB\"У\\''\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rd-CIe1Esz3O",
    "outputId": "9a7e0114-d0ad-4849-f801-104529dbc201"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 131)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.876249\n"
     ]
    }
   ],
   "source": [
    "# функция потерь\n",
    "\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "# подсчитаем ошибку\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYo5YF5Ls0Yk"
   },
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "DGFXAo7Wsz1d"
   },
   "outputs": [],
   "source": [
    "# место для хранения checkpoint\n",
    "checkpoint_dir = '/content/training_checkpoints'\n",
    "# Имя файла checkpoint\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_freq=44*50, # сохраняем каждую 50-ю итерацию - в эпохе 44 батча (это видно при запуске обучения)\n",
    "    save_weights_only=True, # будем сохранять только веса\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "pusf_JlltceU"
   },
   "outputs": [],
   "source": [
    "# Компиляция модели\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_7ZylFUszzS",
    "outputId": "3ab3146a-d83e-4122-e1dd-fcc21b734a79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 21s 346ms/step - loss: 2.4436\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 16s 355ms/step - loss: 1.9419\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 1.6919\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 16s 358ms/step - loss: 1.5325\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 16s 361ms/step - loss: 1.4525\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 16s 362ms/step - loss: 1.3954\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 16s 363ms/step - loss: 1.3670\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 1.3444\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 16s 361ms/step - loss: 1.3255\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 16s 362ms/step - loss: 1.3126\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 16s 362ms/step - loss: 1.2918\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 1.2773\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 1.2552\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 1.2627\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 1.2358\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 16s 367ms/step - loss: 1.1995\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 16s 367ms/step - loss: 1.1797\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 1.1666\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 1.1271\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 1.0928\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 1.0635\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 16s 367ms/step - loss: 1.0448\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 1.0094\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 1.0019\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 16s 366ms/step - loss: 0.9593\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 17s 369ms/step - loss: 0.9267\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 17s 368ms/step - loss: 0.8884\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 16s 367ms/step - loss: 0.8586\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 17s 369ms/step - loss: 0.8327\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 17s 369ms/step - loss: 0.8272\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.8034\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.7549\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.7509\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 17s 371ms/step - loss: 0.7027\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 0.6552\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.6248\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 16s 362ms/step - loss: 0.6110\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 16s 360ms/step - loss: 0.5578\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 16s 363ms/step - loss: 0.5142\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 16s 361ms/step - loss: 0.4829\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 16s 363ms/step - loss: 0.4529\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.4867\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 16s 362ms/step - loss: 0.4491\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 16s 360ms/step - loss: 0.4100\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 16s 359ms/step - loss: 0.3840\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 16s 358ms/step - loss: 0.3614\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 16s 360ms/step - loss: 0.3658\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 0.3661\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.3478\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 17s 389ms/step - loss: 0.3301\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.3276\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 0.3601\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 0.3252\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.3366\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 16s 366ms/step - loss: 0.3193\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 0.3142\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.3043\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 16s 366ms/step - loss: 0.2945\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 17s 370ms/step - loss: 0.3030\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.2872\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 16s 366ms/step - loss: 0.2844\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 16s 366ms/step - loss: 0.2801\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.2779\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 17s 370ms/step - loss: 0.2732\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.2707\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 16s 366ms/step - loss: 0.2681\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 0.2667\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 16s 367ms/step - loss: 0.2626\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.2600\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 17s 368ms/step - loss: 0.2596\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 17s 370ms/step - loss: 0.2587\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 16s 366ms/step - loss: 0.2560\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.2528\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 17s 367ms/step - loss: 0.2502\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 16s 367ms/step - loss: 0.2485\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 0.2475\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 0.2457\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 16s 366ms/step - loss: 0.2439\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 17s 368ms/step - loss: 0.2414\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 17s 369ms/step - loss: 0.2391\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 17s 369ms/step - loss: 0.2335\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.2326\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 0.2306\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.2252\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 0.2726\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 16s 366ms/step - loss: 0.2505\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 0.2318\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 0.2385\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 16s 364ms/step - loss: 0.2536\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 16s 363ms/step - loss: 0.2288\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.2180\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 16s 363ms/step - loss: 0.2106\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.2082\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 16s 366ms/step - loss: 0.2053\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 16s 365ms/step - loss: 0.1984\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 16s 366ms/step - loss: 0.2000\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 16s 367ms/step - loss: 0.2108\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 16s 367ms/step - loss: 0.1943\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 17s 369ms/step - loss: 0.1904\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 17s 386ms/step - loss: 0.1857\n"
     ]
    }
   ],
   "source": [
    "#обучение модели\n",
    "EPOCHS = 100\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dl6Wg-oTszuK",
    "outputId": "8fde9c66-819d-4891-884f-e4a54560cf92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 131) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "#предсказание модели\n",
    "example_batch_predictions = model(input_example_batch)\n",
    "print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "qjKgRJmP5A83"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0V4YCOCU5Cj1",
    "outputId": "7525048f-dfa5-48e3-a16e-0fa29f6e6059"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'ц,\\n                        Давал три бала ежегодно\\n                        И промотался наконец.\\n   '\n",
      "\n",
      "Next Char Predictions: \n",
      " 'а\\n                        Тивнл яри бала ежегодно\\n                        И,воомотался наконец.\\n    '\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhJEUtw51sVa"
   },
   "source": [
    "### Генерация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "9sa4y2eJ5Ipr",
    "outputId": "cd52b6df-419f-4c4d-d111-77ddac9cc92c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/training_checkpoints/ckpt_100'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Находим имя файла последней сохраненной контрольной точки\n",
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "lUYLFUii5Im4"
   },
   "outputs": [],
   "source": [
    "#строим модель\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "#загружаем веса из последней сохраненной контрольной точки в модель\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eh_-r2yq5IhJ",
    "outputId": "8d40baf0-a0f8-412a-fe3d-493ab4db2cce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (1, None, 256)            33536     \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (1, None, 1024)           5246976   \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (1, None, 1024)           8392704   \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (1, None, 1024)           8392704   \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (1, None, 1024)           8392704   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (1, None, 131)            134275    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,592,899\n",
      "Trainable params: 30,592,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#информация о модели\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "13GNNQ8T5Iew"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # Этап оценки (генерация текста с использованием обученной модели)\n",
    "\n",
    "    # число букв для генераци\n",
    "    num_generate = 100\n",
    "\n",
    "    # Преобразование начальной строки в числа (векторизация)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    #Возвращаем тензор с осью длины 1, вставленной первой в индекс\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Пустая строка для хранения результатов\n",
    "    text_generated = []\n",
    "\n",
    "    # Низкая температура приводит к более предсказуемому тексту.\n",
    "    # Более высокая температура приводит к более неожиданному тексту.\n",
    "    temperature = 0.001\n",
    "\n",
    "    # здесь batch size == 1\n",
    "    # сбрасываем состояния всех слоев в модели\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "\n",
    "        #получаем предсказания модели\n",
    "        predictions = model(input_eval)\n",
    "\n",
    "        #удаляем первую размерность в предсказании\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # использование категориального распределения для прогнозирования символа, возвращаемого моделью\n",
    "        predictions = predictions / temperature\n",
    "\n",
    "        # выберем последний токен из отсэмплированных предсказаний[-1], т.к. именно он будет предсказанным следующим токеном в строке\n",
    "        # индекс 0 - выбираем именно индекс токена (помимо него выводится еще размер [1]и тип [2])\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "        # print(predicted_id) \n",
    "\n",
    "        # Передаем предсказанный символ в качестве следующего ввода в модель, по нему будет предсказывать следующий символ\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        #сохраняем предсказанную букву\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EyD6oHGVAy3i",
    "outputId": "ed90a601-e42c-4d39-8db6-b874bd01c438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вот он идет был обмотом,\n",
      "                        По старине торжествовали\n",
      "                        И в самом ужас\n"
     ]
    }
   ],
   "source": [
    "text_ = generate_text(model, start_string=u\"Вот он идет \")\n",
    "print(text_)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "web9_hw.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
