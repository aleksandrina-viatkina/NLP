{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "web9_hw_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание к вебинару 9\n",
        "\n",
        "Задание: обучить генератор текстов\n",
        "* В этом ноутбуке попробуем генерировать текст не по символам, а по токенам."
      ],
      "metadata": {
        "id": "tDq139uDxcbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install stop_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg3JyWjUPSCk",
        "outputId": "856f2364-ee58-4a45-ad06-f26a502738f1"
      },
      "execution_count": 462,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: stop_words in /usr/local/lib/python3.7/dist-packages (2018.7.23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 463,
      "metadata": {
        "id": "DGHeo6gkxa51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71fc6f3e-1b40-43f4-d3c2-472ca0d8a7c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from string import punctuation\n",
        "from stop_words import get_stop_words"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2-O6xtX1rLj",
        "outputId": "5fdbc65f-89cc-4026-8a62-ebe93db21773"
      },
      "execution_count": 464,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = '/content/evgenyi_onegin.txt'"
      ],
      "metadata": {
        "id": "CmR_wHmm1tU9"
      },
      "execution_count": 465,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBtQ5nLN1tS5",
        "outputId": "dba30f2c-dff6-417d-b62b-e9348f53f9d8"
      },
      "execution_count": 466,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 286984 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Выведем фрагмент текста\n",
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1BYW9xK1tQj",
        "outputId": "f6a61681-b846-47b0-b923-c50e134bb375"
      },
      "execution_count": 467,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Александр Сергеевич Пушкин\n",
            "\n",
            "                                Евгений Онегин\n",
            "                                Роман в стихах\n",
            "\n",
            "                        Не мысля гордый свет забавить,\n",
            "                        Вниманье дружбы возлюбя,\n",
            "                        Хотел бы я тебе представить\n",
            "                        Залог достойнее тебя,\n",
            "                        Достойнее души прекрасной,\n",
            "                        Святой исполненной мечты,\n",
            "                        Поэзии живой и ясной,\n",
            "                        Высо\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxqTyt1dP-P3",
        "outputId": "d083c0bd-3fc8-4f16-f56c-d99920d644c1"
      },
      "execution_count": 468,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 468
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sw = get_stop_words(\"ru\") + stopwords.words('russian')\n",
        "punkt = list(\n",
        "    punctuation)\n",
        "noise = set(sw + punkt)"
      ],
      "metadata": {
        "id": "PIEiO_P8PpWF"
      },
      "execution_count": 469,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# токенизация текста \n",
        "\n",
        "def make_tokens(text):\n",
        "    return [token for token in word_tokenize(text) if token not in noise and token.isalpha()]\n",
        "tokens = make_tokens(text)"
      ],
      "metadata": {
        "id": "lHpbN9TTEZqL"
      },
      "execution_count": 470,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создадим словарь уникальных токенов в тексте\n",
        "vocab = sorted(set(tokens))\n",
        "print('{} unique characters'.format(len(vocab)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxrsULVi1tOP",
        "outputId": "53b6e726-626c-4f30-a78e-b7884a888aaf"
      },
      "execution_count": 471,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8911 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab[-10:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5WqJZou1tL2",
        "outputId": "18e6e169-4e16-4642-d3f7-e7f75f80d720"
      },
      "execution_count": 472,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['яснее',\n",
              " 'яснеет',\n",
              " 'ясно',\n",
              " 'ясной',\n",
              " 'ясностию',\n",
              " 'ясностью',\n",
              " 'ясною',\n",
              " 'ясные',\n",
              " 'ясным',\n",
              " 'ящик']"
            ]
          },
          "metadata": {},
          "execution_count": 472
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Задаем отображения из множества уникальных букв в множество индексов\n",
        "token2idx = {u:i for i, u in enumerate(vocab)} # словарь {индекс: токен}\n",
        "\n",
        "idx2token = np.array(vocab) # array из символов словаря (можно по индексу извлекать токен)"
      ],
      "metadata": {
        "id": "rl5ojqWa1tJy"
      },
      "execution_count": 473,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx2token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUdSQdlJ1tHe",
        "outputId": "9caa96b4-662f-4ba1-fa0b-a3b0a67ba86b"
      },
      "execution_count": 474,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Annеttе', 'Au', 'Byron', ..., 'ясные', 'ясным', 'ящик'],\n",
              "      dtype='<U18')"
            ]
          },
          "metadata": {},
          "execution_count": 474
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Теперь переводим все символы текста в индексы - на выходе array из индексов\n",
        "text_as_int = np.array([token2idx[c] for c in tokens])"
      ],
      "metadata": {
        "id": "IUMFu5yb7Gv9"
      },
      "execution_count": 475,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_as_int"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP4YfojU7NWf",
        "outputId": "2dfca1d9-97eb-4d09-f94f-0fc910da1f9f"
      },
      "execution_count": 476,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 153, 1743, 1609, ..., 1213, 4921,  808])"
            ]
          },
          "metadata": {},
          "execution_count": 476
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:500]), print(text_as_int[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mqr2dZ1SBsb9",
        "outputId": "aa5c34b8-99a4-4daa-e7ca-6ea579380d37"
      },
      "execution_count": 477,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Александр Сергеевич Пушкин\n",
            "\n",
            "                                Евгений Онегин\n",
            "                                Роман в стихах\n",
            "\n",
            "                        Не мысля гордый свет забавить,\n",
            "                        Вниманье дружбы возлюбя,\n",
            "                        Хотел бы я тебе представить\n",
            "                        Залог достойнее тебя,\n",
            "                        Достойнее души прекрасной,\n",
            "                        Святой исполненной мечты,\n",
            "                        Поэзии живой и ясной,\n",
            "                        Высо\n",
            "[ 153 1743 1609  582 1209 1666 7751 1062 5046 3223 7185 3800  338 3616\n",
            " 2871 2105 6487  649 3571  547 3660 6510 1726 4224 4840 1470 3763 8904\n",
            "  409 3634 6733 1135 7106 6623 1528 7563 5928 3129 1424 6243 1576 4124\n",
            " 1065 6025 4922 3798  194 4564 2601 1087 8242 2030 8549 5055  708 7299\n",
            " 3229 3897  415 1283  708 3779 8105 8711 7652  794  414    7  988 3676\n",
            " 7159 8672 6436  803 8827 3920 1207 8223 3966  708 3063  587 6589 3609\n",
            " 5159 1135 2458 7381 1685 2476 7322 5413 1062 5774 8749 6753  764 5360\n",
            " 4369 1421 3802  594 6129 6288 1331 6102 4576  318 3641  803 8660 2881\n",
            "    8 1903 3638 4936 6057  890 6810 6408  389 2886  692 1049 7054  566\n",
            "  927 1680 1685 3117 4916 7077  181 6470 7259 8622 1395 6168 1209 3492\n",
            " 6645 1659 2512 1076  422 7047  734 2429 8691 1908 5289 3337 1135 2992\n",
            " 7249    9 1789 5739 2383  537 3772 5723  487 2249 3685  708 6696 1888\n",
            "  584 8573 1840   25 8528 1458   27 7490 1646 7007 4845   27 8485 8216\n",
            " 2151 4164 3471 2062 8829 1062 3513 4962 7837 1779 8756 2498  708  886\n",
            " 7141 3339 2850   10  803 8856 5050 1545  583 1434 5078 3316 5270   27\n",
            " 6668 3393  374 1209 7214 1238 6332 4907  761   99 4667 5554  708 8229\n",
            " 7185 1207 7565  981 4180 5962  869 4757 7991  708 4324 5320 2131 1708\n",
            " 7021 2150 8333 4845   41 1015 8459 6275 1903 2949 7402 2455 1991 5295\n",
            " 2415 1209 4889 4895 1886 7024 7835 2061 4764 5855  738 7938 7987  181\n",
            " 6604 6877  823 7423 1685 8458 2780 4080 2114 4951 2574 7666  708 2856\n",
            " 8323 3363 1169 5265 8845   42  866 4914 3100 5427 1903 6435 1207 4073\n",
            " 2151 8850 6862 1457 2188  264 4408 5971 6351  139  484 6263 3293  720\n",
            " 2186 7750 1207 7134 4185 5797  264 8580 6810  262 4020 1135 3477 4860\n",
            " 2233 1242 1667 5186 3477 2110 5832   43  410 7804 4195  522 3997 3770\n",
            " 8831 1062 8891 8553  761 2368 5738  241  446 2070  675 8688  149 1804\n",
            "  708 3145 8841 1948 8330 7878  761 3267 2448  708 3760 1062 4094  803\n",
            " 6728 6677 4184 1250 6282  708 4020 5709 3887   44  391 4073  582 1310\n",
            " 5256 1135 4233 3116 2150 4073 8002 5158 2150 4163  708 8169 5018 5755\n",
            " 2150 3927 8604  587 8114 4586  260 5159 7804 5270  825 2947 1034  619\n",
            " 7783 4410 1724 2617 2420 5051  264  989 3159 7743  275  752   11   45\n",
            "  761 4646 1901 5081 6993 1630 3967 2653  760 4991 4169 2197 3224 6341\n",
            "  339 4182 6845  761 8085 4948  761 5988 4449  264 7296 5973 5201 1179\n",
            " 3672 5563 4742  761 8330 3829  761 2749 2563 5266 1884 3452 6298  221\n",
            " 6339 7439   46  761 8330 4255 5385 2181 5217 4178 1596 5781 3277 1550\n",
            " 4599 3802  900 4864 8340 1071 6490 2035 7810 6041 1074 4548 5583  992\n",
            " 8128 6570 1388 7299 3994 1498 4736  528 7974 7208]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 477
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Подготовка данных к обучению"
      ],
      "metadata": {
        "id": "jD9O5oKaEA0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Максимальная длина предложения (максимальное количество слов в батче) для входных данных (в буквах)\n",
        "tokens_length = 200\n",
        "\n",
        "# Количество эпох\n",
        "examples_per_epoch = len(text)//(tokens_length+1)\n",
        "\n",
        "# создаем экземпляр датасета из идексов токенов\n",
        "tokens_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in tokens_dataset.take(5):\n",
        "    print(idx2token[i.numpy()], len(tokens_dataset)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQTJbGozBsZn",
        "outputId": "3c2d4bfe-73b0-422a-9bd7-94bd998e17e0"
      },
      "execution_count": 478,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Александр 17362\n",
            "Сергеевич 17362\n",
            "Пушкин 17362\n",
            "Евгений 17362\n",
            "Онегин 17362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем последовательность из батчей токенов с установленной длиной батча\n",
        "sequences = tokens_dataset.batch(tokens_length+1, drop_remainder = True)"
      ],
      "metadata": {
        "id": "33zahMcbBsXV"
      },
      "execution_count": 479,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sequences), len(tokens), len(tokens_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8al8FJZ-HrNY",
        "outputId": "ce2130eb-6ba8-44c4-97cb-00445feab297"
      },
      "execution_count": 480,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86, 17362, 17362)"
            ]
          },
          "metadata": {},
          "execution_count": 480
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences:\n",
        "  print(seq)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5noiLU4KshX",
        "outputId": "37194ee4-c54e-4ee9-9dda-09a3d929b65c"
      },
      "execution_count": 481,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[ 153 1743 1609  582 1209 1666 7751 1062 5046 3223 7185 3800  338 3616\n",
            " 2871 2105 6487  649 3571  547 3660 6510 1726 4224 4840 1470 3763 8904\n",
            "  409 3634 6733 1135 7106 6623 1528 7563 5928 3129 1424 6243 1576 4124\n",
            " 1065 6025 4922 3798  194 4564 2601 1087 8242 2030 8549 5055  708 7299\n",
            " 3229 3897  415 1283  708 3779 8105 8711 7652  794  414    7  988 3676\n",
            " 7159 8672 6436  803 8827 3920 1207 8223 3966  708 3063  587 6589 3609\n",
            " 5159 1135 2458 7381 1685 2476 7322 5413 1062 5774 8749 6753  764 5360\n",
            " 4369 1421 3802  594 6129 6288 1331 6102 4576  318 3641  803 8660 2881\n",
            "    8 1903 3638 4936 6057  890 6810 6408  389 2886  692 1049 7054  566\n",
            "  927 1680 1685 3117 4916 7077  181 6470 7259 8622 1395 6168 1209 3492\n",
            " 6645 1659 2512 1076  422 7047  734 2429 8691 1908 5289 3337 1135 2992\n",
            " 7249    9 1789 5739 2383  537 3772 5723  487 2249 3685  708 6696 1888\n",
            "  584 8573 1840   25 8528 1458   27 7490 1646 7007 4845   27 8485 8216\n",
            " 2151 4164 3471 2062 8829 1062 3513 4962 7837 1779 8756 2498  708  886\n",
            " 7141 3339 2850   10  803], shape=(201,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in sequences.take(5):\n",
        "    print(repr(' '.join(idx2token[item.numpy()])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzOwSNfaE7GT",
        "outputId": "6832174f-508d-4ecc-da5d-236c86e18a62"
      },
      "execution_count": 482,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Александр Сергеевич Пушкин Евгений Онегин Роман стихах Не мысля гордый свет забавить Вниманье дружбы возлюбя Хотел представить Залог достойнее Достойнее души прекрасной Святой исполненной мечты Поэзии живой ясной Высоких дум простоты Но рукой пристрастной Прими собранье пестрых глав Полусмешных полупечальных Простонародных идеальных Небрежный плод моих забав Бессонниц легких вдохновений Незрелых увядших Ума холодных наблюдений И сердца горестных замет ГЛАВА ПЕРВАЯ И жить торопится чувствовать спешит Кн Вяземский I Мой дядя самых честных правил Когда шутку занемог Он уважать заставил И выдумать Его пример другим наука Но боже скука С больным сидеть ночь Не отходя шагу прочь Какое низкое коварство Полуживого забавлять Ему подушки поправлять Печально подносить лекарство Вздыхать думать Когда черт возьмет II Так думал молодой повеса Летя пыли почтовых Всевышней волею Зевеса Наследник родных Друзья Людмилы Руслана С героем моего романа Без предисловий сей час Позвольте познакомить Онегин добрый приятель Родился брегах Невы Где родились Или блистали читатель Там некогда гулял Но вреден север III Служив отлично благородно Долгами жил отец Давал бала ежегодно И промотался Судьба Евгения хранила Сперва Madame ходила Потом Monsieur сменил Ребенок резов мил Monsieur француз убогой Чтоб измучилось дитя Учил шутя Не докучал моралью строгой Слегка шалости бранил И Летний сад гулять водил IV Когда'\n",
            "'юности мятежной Пришла Евгению Пора надежд грусти нежной Monsieur прогнали двора Вот Онегин свободе Острижен последней моде Как dandy лондонский одет И увидел свет Он совершенно Мог изъясняться писал Легко мазурку танцевал И кланялся непринужденно Чего Свет решил Что умен мил V Мы учились понемногу Так воспитаньем слава богу У немудрено блеснуть Онегин мненью многих Судей решительных строгих Ученый малый педант Имел счастливый талант Без принужденья разговоре Коснуться слегка С ученым видом знатока Хранить молчанье важном споре И возбуждать улыбку дам Огнем нежданных эпиграмм VI Латынь моды вышла ныне Так правду Он знал Чтоб эпиграфы разбирать Потолковать Ювенале В конце письма поставить vale Да помнил греха Из Энеиды стиха Он рыться имел охоты В хронологической пыли Бытописания земли Но дней минувших анекдоты От Ромула наших дней Хранил памяти VII Высокой страсти имея Для звуков жизни щадить Не ямба хорея Как бились отличить Бранил Гомера Феокрита Зато читал Адама Смита И глубокой эконом То умел судить Как государство богатеет И живет Не золота Когда простой продукт имеет Отец понять И земли отдавал залог VIII Всего знал Евгений Пересказать недосуг Но истинный гений Что знал тверже наук Что измлада И труд мука отрада Что занимало целый Его тоскующую лень Была наука страсти нежной'\n",
            "'Которую воспел Назон За страдальцем кончил Свой век блестящий мятежный В Молдавии глуши степей Вдали Италии IX X Как лицемерить Таить надежду ревновать Разуверять заставить верить Казаться мрачным изнывать Являться гордым послушным Внимательным иль равнодушным Как томно молчалив Как пламенно красноречив В сердечных письмах небрежен Одним дыша одно любя Как умел забыть Как взор быстр нежен Стыдлив дерзок порой Блистал послушною слезой XI Как умел казаться новым Шутя невинность изумлять Пугать отчаяньем готовым Приятной лестью забавлять Ловить минуту умиленья Невинных предубежденья Умом страстью побеждать Невольной ласки ожидать Молить требовать признанья Подслушать сердца звук Преследовать любовь Добиться тайного свиданья И наедине Давать уроки тишине XII Как тревожить Сердца кокеток записных Когда хотелось уничтожить Ему соперников Как язвительно злословил Какие сети готовил Но блаженные мужья С оставались друзья Его ласкал супруг лукавый Фобласа давний ученик И недоверчивый старик И рогоносец величавый Всегда довольный Своим обедом женой XIII XIV XV Бывало постеле К записочки несут Что Приглашенья В деле Три дома вечер зовут Там бал детский праздник Куда поскачет проказник С начнет Все равно Везде поспеть немудрено Покамест утреннем уборе Надев широкий боливар Онегин едет бульвар И гуляет просторе Пока недремлющий брегет Не прозвонит обед XVI Уж темно санки садится Пади пади раздался крик'\n",
            "'Морозной пылью серебрится Его бобровый воротник К Talon помчался уверен Что ждет Каверин Вошел пробка потолок Вина кометы брызнул ток Пред окровавленный И трюфли роскошь юных Французской кухни лучший цвет И Страсбурга пирог нетленный Меж сыром лимбургским живым И ананасом золотым XVII Еще бокалов жажда просит Залить горячий жир котлет Но звон брегета доносит Что новый начался балет Театра злой законодатель Непостоянный обожатель Очаровательных актрис Почетный гражданин кулис Онегин полетел театру Где вольностью дыша Готов охлопать entrechat Обшикать Федру Клеопатру Моину вызвать Чтоб слышали XVIII Волшебный край стары годы Сатиры смелый властелин Блистал Фонвизин друг свободы И переимчивый Княжнин Там Озеров невольны дани Народных слез рукоплесканий С младой Семеновой делил Там Катенин воскресил Корнеля гений величавый Там вывел колкий Шаховской Своих комедий шумный рой Там Дидло венчался славой Там сению кулис Младые дни неслись XIX Мои богини Внемлите печальный глас Все ль ль девы Сменив заменили Услышу ль вновь хоры Узрю русской Терпсихоры Душой исполненный полет Иль взор унылый найдет Знакомых лиц сцене скучной И устремив чуждый свет Разочарованный лорнет Веселья зритель равнодушный Безмолвно зевать И былом воспоминать XX Театр полон ложи блещут Партер кресла кипит В райке нетерпеливо плещут И взвившись занавес шумит Блистательна полувоздушна Смычку волшебному послушна Толпою нимф'\n",
            "'окружена Стоит Истомина Одной ногой касаясь пола Другою медленно кружит И прыжок летит Летит пух уст Эола То стан совьет разовьет И быстрой ножкой ножку бьет XXI Все хлопает Онегин входит Идет меж кресел ногам Двойной лорнет скосясь наводит На ложи незнакомых дам Все ярусы окинул взором Все видел лицами убором Ужасно недоволен С мужчинами сторон Раскланялся сцену В большом рассеянье взглянул Отворотился зевнул И молвил Всех смену Балеты терпел Но Дидло надоел XXII Еще амуры черти змеи На сцене скачут шумят Еще усталые лакеи На шубах подъезда спят Еще перестали топать Сморкаться кашлять шикать хлопать Еще снаружи внутри Везде блистают фонари Еще прозябнув бьются кони Наскуча упряжью И кучера огней Бранят господ бьют ладони А Онегин вышел Домой одеться едет XXIII Изображу ль картине верной Уединенный кабинет Где мод воспитанник примерный Одет раздет вновь одет Все прихоти обильной Торгует Лондон щепетильный И Балтическим волнам За лес сало возит Все Париже вкус голодный Полезный промысел избрав Изобретает забав Для роскоши неги модной Все украшало кабинет Философа осьмнадцать XXIV Янтарь трубках Цареграда Фарфор бронза столе И чувств изнеженных отрада Духи граненом хрустале Гребенки пилочки стальные Прямые ножницы кривые И щетки тридцати родов И ногтей зубов Руссо замечу мимоходом Не понять Грим Смел'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разбиваем каждый батч на признаки и целевую переменную (следующую букву)\n",
        "def split_input_target(batch):\n",
        "    input_text = batch[:-1]\n",
        "    target_text = batch[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "#применяем функцию split_input_target ко всем батчам -> таким образом формируем новый датасет\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "prpupE8ZN66_"
      },
      "execution_count": 483,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset:\n",
        "    print(f'Количество батчей: {len(dataset)}')\n",
        "    print(f'Данные: {input_example}')\n",
        "    print(f'Целевая переменная: {target_example}')\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO9Z2RReN692",
        "outputId": "55876876-d842-4168-ef0c-e4828b8e0367"
      },
      "execution_count": 484,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество батчей: 86\n",
            "Данные: [ 153 1743 1609  582 1209 1666 7751 1062 5046 3223 7185 3800  338 3616\n",
            " 2871 2105 6487  649 3571  547 3660 6510 1726 4224 4840 1470 3763 8904\n",
            "  409 3634 6733 1135 7106 6623 1528 7563 5928 3129 1424 6243 1576 4124\n",
            " 1065 6025 4922 3798  194 4564 2601 1087 8242 2030 8549 5055  708 7299\n",
            " 3229 3897  415 1283  708 3779 8105 8711 7652  794  414    7  988 3676\n",
            " 7159 8672 6436  803 8827 3920 1207 8223 3966  708 3063  587 6589 3609\n",
            " 5159 1135 2458 7381 1685 2476 7322 5413 1062 5774 8749 6753  764 5360\n",
            " 4369 1421 3802  594 6129 6288 1331 6102 4576  318 3641  803 8660 2881\n",
            "    8 1903 3638 4936 6057  890 6810 6408  389 2886  692 1049 7054  566\n",
            "  927 1680 1685 3117 4916 7077  181 6470 7259 8622 1395 6168 1209 3492\n",
            " 6645 1659 2512 1076  422 7047  734 2429 8691 1908 5289 3337 1135 2992\n",
            " 7249    9 1789 5739 2383  537 3772 5723  487 2249 3685  708 6696 1888\n",
            "  584 8573 1840   25 8528 1458   27 7490 1646 7007 4845   27 8485 8216\n",
            " 2151 4164 3471 2062 8829 1062 3513 4962 7837 1779 8756 2498  708  886\n",
            " 7141 3339 2850   10]\n",
            "Целевая переменная: [1743 1609  582 1209 1666 7751 1062 5046 3223 7185 3800  338 3616 2871\n",
            " 2105 6487  649 3571  547 3660 6510 1726 4224 4840 1470 3763 8904  409\n",
            " 3634 6733 1135 7106 6623 1528 7563 5928 3129 1424 6243 1576 4124 1065\n",
            " 6025 4922 3798  194 4564 2601 1087 8242 2030 8549 5055  708 7299 3229\n",
            " 3897  415 1283  708 3779 8105 8711 7652  794  414    7  988 3676 7159\n",
            " 8672 6436  803 8827 3920 1207 8223 3966  708 3063  587 6589 3609 5159\n",
            " 1135 2458 7381 1685 2476 7322 5413 1062 5774 8749 6753  764 5360 4369\n",
            " 1421 3802  594 6129 6288 1331 6102 4576  318 3641  803 8660 2881    8\n",
            " 1903 3638 4936 6057  890 6810 6408  389 2886  692 1049 7054  566  927\n",
            " 1680 1685 3117 4916 7077  181 6470 7259 8622 1395 6168 1209 3492 6645\n",
            " 1659 2512 1076  422 7047  734 2429 8691 1908 5289 3337 1135 2992 7249\n",
            "    9 1789 5739 2383  537 3772 5723  487 2249 3685  708 6696 1888  584\n",
            " 8573 1840   25 8528 1458   27 7490 1646 7007 4845   27 8485 8216 2151\n",
            " 4164 3471 2062 8829 1062 3513 4962 7837 1779 8756 2498  708  886 7141\n",
            " 3339 2850   10  803]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print('Input data: ', repr(' '.join(idx2token[input_example.numpy()])))\n",
        "    print('Target data:', repr(' '.join(idx2token[target_example.numpy()])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpKEEp3UQJRD",
        "outputId": "35b36de0-06e1-4ff6-a0e4-2fb3e87a0410"
      },
      "execution_count": 485,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data:  'Александр Сергеевич Пушкин Евгений Онегин Роман стихах Не мысля гордый свет забавить Вниманье дружбы возлюбя Хотел представить Залог достойнее Достойнее души прекрасной Святой исполненной мечты Поэзии живой ясной Высоких дум простоты Но рукой пристрастной Прими собранье пестрых глав Полусмешных полупечальных Простонародных идеальных Небрежный плод моих забав Бессонниц легких вдохновений Незрелых увядших Ума холодных наблюдений И сердца горестных замет ГЛАВА ПЕРВАЯ И жить торопится чувствовать спешит Кн Вяземский I Мой дядя самых честных правил Когда шутку занемог Он уважать заставил И выдумать Его пример другим наука Но боже скука С больным сидеть ночь Не отходя шагу прочь Какое низкое коварство Полуживого забавлять Ему подушки поправлять Печально подносить лекарство Вздыхать думать Когда черт возьмет II Так думал молодой повеса Летя пыли почтовых Всевышней волею Зевеса Наследник родных Друзья Людмилы Руслана С героем моего романа Без предисловий сей час Позвольте познакомить Онегин добрый приятель Родился брегах Невы Где родились Или блистали читатель Там некогда гулял Но вреден север III Служив отлично благородно Долгами жил отец Давал бала ежегодно И промотался Судьба Евгения хранила Сперва Madame ходила Потом Monsieur сменил Ребенок резов мил Monsieur француз убогой Чтоб измучилось дитя Учил шутя Не докучал моралью строгой Слегка шалости бранил И Летний сад гулять водил IV'\n",
            "Target data: 'Сергеевич Пушкин Евгений Онегин Роман стихах Не мысля гордый свет забавить Вниманье дружбы возлюбя Хотел представить Залог достойнее Достойнее души прекрасной Святой исполненной мечты Поэзии живой ясной Высоких дум простоты Но рукой пристрастной Прими собранье пестрых глав Полусмешных полупечальных Простонародных идеальных Небрежный плод моих забав Бессонниц легких вдохновений Незрелых увядших Ума холодных наблюдений И сердца горестных замет ГЛАВА ПЕРВАЯ И жить торопится чувствовать спешит Кн Вяземский I Мой дядя самых честных правил Когда шутку занемог Он уважать заставил И выдумать Его пример другим наука Но боже скука С больным сидеть ночь Не отходя шагу прочь Какое низкое коварство Полуживого забавлять Ему подушки поправлять Печально подносить лекарство Вздыхать думать Когда черт возьмет II Так думал молодой повеса Летя пыли почтовых Всевышней волею Зевеса Наследник родных Друзья Людмилы Руслана С героем моего романа Без предисловий сей час Позвольте познакомить Онегин добрый приятель Родился брегах Невы Где родились Или блистали читатель Там некогда гулял Но вреден север III Служив отлично благородно Долгами жил отец Давал бала ежегодно И промотался Судьба Евгения хранила Сперва Madame ходила Потом Monsieur сменил Ребенок резов мил Monsieur француз убогой Чтоб измучилось дитя Учил шутя Не докучал моралью строгой Слегка шалости бранил И Летний сад гулять водил IV Когда'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Построение модели"
      ],
      "metadata": {
        "id": "Vaz-wkhTRx7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# размер батча\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# размер буфера для перемешивания данных\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "# перемешивание разделенных данных\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "jFj0g7Z2QJNv"
      },
      "execution_count": 486,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jde1dXwyJlwu",
        "outputId": "160f2c7e-178e-4ebe-ce94-27235a967e81"
      },
      "execution_count": 487,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 487
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Длина словаря\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Длина выходного эмбеддинга\n",
        "embedding_dim = 512\n",
        "\n",
        "# Количество скрытых состояний в RNN слое \n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "vyl2qomVQJKo"
      },
      "execution_count": 488,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                  batch_input_shape=[batch_size, None]),\n",
        "                                 \n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "         tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "        \n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "                                   \n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "xR8-yQM-Srjt"
      },
      "execution_count": 489,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "P0S4yAlYN7AY"
      },
      "execution_count": 490,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvWFtxhXrBla",
        "outputId": "60ffe555-0fc3-440d-d65e-c945768c8863"
      },
      "execution_count": 491,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (16, None, 512)           4562432   \n",
            "                                                                 \n",
            " lstm_47 (LSTM)              (16, None, 1024)          6295552   \n",
            "                                                                 \n",
            " lstm_48 (LSTM)              (16, None, 1024)          8392704   \n",
            "                                                                 \n",
            " lstm_49 (LSTM)              (16, None, 1024)          8392704   \n",
            "                                                                 \n",
            " lstm_50 (LSTM)              (16, None, 1024)          8392704   \n",
            "                                                                 \n",
            " dense_12 (Dense)            (16, None, 8911)          9133775   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45,169,871\n",
            "Trainable params: 45,169,871\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Сделаем предсказание без обучения модели**"
      ],
      "metadata": {
        "id": "gzN7K11Osvcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape,\" # (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTzYZ1PKVjEU",
        "outputId": "1f4ae800-3847-48e5-8702-ac52fe1312ac"
      },
      "execution_count": 492,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16, 200, 8911)  # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_predictions[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IGh01zlVjBi",
        "outputId": "e89fa631-507c-4248-9461-89789e34f4f5"
      },
      "execution_count": 493,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(200, 8911), dtype=float32, numpy=\n",
              "array([[-2.16110675e-06,  5.02403191e-06, -5.07310779e-06, ...,\n",
              "        -7.71862233e-06,  4.34601361e-06,  7.25143479e-07],\n",
              "       [-5.76603679e-06,  1.31537136e-05, -1.53526271e-05, ...,\n",
              "        -1.60427535e-05,  7.12364590e-06, -6.58121098e-06],\n",
              "       [-1.73401659e-05,  2.50995981e-05, -3.42587991e-05, ...,\n",
              "        -2.06162458e-05,  1.82816837e-06, -2.45668871e-05],\n",
              "       ...,\n",
              "       [ 3.52714414e-04, -7.33937195e-04,  9.89198452e-04, ...,\n",
              "        -1.06927146e-04, -7.35093257e-04, -4.51122323e-05],\n",
              "       [ 3.26732261e-04, -7.33984110e-04,  1.10001664e-03, ...,\n",
              "        -1.56889160e-04, -7.79844820e-04,  2.60967113e-06],\n",
              "       [ 2.75660976e-04, -7.07440719e-04,  1.19228906e-03, ...,\n",
              "        -2.09166436e-04, -8.00655223e-04,  4.99618400e-05]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 493
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сэмплируем предсказание \n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1) #количество независимых выборок 1\n",
        "\n",
        "#убираем лишнюю размерность (список индексов)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvpyXmyZBsU1",
        "outputId": "5fb97adb-0555-4dbf-90c1-3dde095ba80c"
      },
      "execution_count": 494,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8194, 5546, 8726, 1113, 6874, 7619, 3815, 8057, 8776, 5085, 4726,\n",
              "       2121, 5310, 5850, 7525, 2805, 8686, 4963, 2254, 5166,  635, 1313,\n",
              "       3142, 1904, 8118, 2654, 7635, 5479, 4905, 6062, 8327, 3316, 2730,\n",
              "       2715, 4426, 1719, 1338, 2108, 1149,  419, 8385, 7111, 5161, 5617,\n",
              "       5694,  143, 1294, 1246, 1389,  834, 5092, 7743, 6963, 3010, 5993,\n",
              "       5735,  938, 5063, 2698, 2124, 5788, 4227, 4242, 1562, 1956, 5909,\n",
              "       4722, 4926, 4699, 1599, 3203, 1005, 6714, 1402, 7768, 6564, 3034,\n",
              "       7215, 5478, 5219, 5071, 7157, 1996, 7491, 1648, 3906, 2921, 8132,\n",
              "       4395, 1461, 5433, 2490, 1373, 5284, 5577, 6293, 2129, 6753, 4607,\n",
              "       6565, 5519, 5270, 7883,  885, 3437, 1246, 4758, 1090, 1567, 8385,\n",
              "       8510, 2902, 1158, 2150, 3837, 2901, 6550, 3530, 7644,   53, 1916,\n",
              "       1779, 1549, 5763, 6633, 1395, 4588, 4778, 8827, 3406,  976, 1347,\n",
              "       4251,  628, 8610, 3329, 3823,  629, 7940, 2670, 3144,  283, 6185,\n",
              "       3823,  934, 3750, 8790, 7925, 4596, 1175,  678, 2679, 5235, 1348,\n",
              "       6846, 4794,  874, 7287, 8174, 1980, 3705, 4094, 5385, 4259,  781,\n",
              "       8629, 2102, 5533, 1233, 3529, 3277, 1118, 3579, 5678, 4508, 7598,\n",
              "       7120,  983, 7313, 7350, 1369, 6861, 3964, 2492, 2511, 5243, 6085,\n",
              "       2573, 6230, 1130, 4074, 8845, 4283, 1450,  430,  327, 2492,  638,\n",
              "        466, 3240])"
            ]
          },
          "metadata": {},
          "execution_count": 494
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input: \\n\", repr(\" \".join(idx2token[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\" \".join(idx2token[sampled_indices ])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7F0tNQysQDE",
        "outputId": "f473ec67-a58c-4726-b325-66232707393f"
      },
      "execution_count": 495,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: \n",
            " 'пень Становится Гильо смущенный Плащи бросают врага Зарецкий тридцать шага Отмерил точностью отменной Друзей развел крайний след И взял свой пистолет XXX Теперь сходитесь Хладнокровно Еще целя врага Походкой твердой тихо ровно Четыре перешли шага Четыре смертные ступени Свой пистолет Евгений Не преставая наступать Стал тихо подымать Вот шагов ступили И Ленский жмуря левый глаз Стал целить Онегин выстрелил Пробили Часы урочные поэт Роняет молча пистолет XXXI На грудь кладет тихонько руку И падает Туманный взор Изображает смерть муку Так медленно скату гор На солнце искрами блистая Спадает глыба снеговая Мгновенным холодом облит Онегин юноше спешит Глядит зовет напрасно Его Младой певец Нашел безвременный конец Дохнула буря цвет прекрасный Увял утренней заре Потух огонь алтаре XXXII Недвижим лежал странен Был томный мир чела Под грудь навылет ранен Дымясь раны кровь текла Тому одно мгновенье В сем сердце билось вдохновенье Вражда надежда любовь Играла кипела кровь Теперь доме опустелом Все тихо темно Замолкло навсегда Закрыты ставни окны мелом Забелены Хозяйки А бог весть Пропал след XXXIII Приятно дерзкой эпиграммой Взбесить оплошного врага Приятно зреть упрямо Склонив бодливые рога Невольно зеркало глядится И узнавать стыдится Приятней друзья Завоет сдуру Еще приятнее молчанье Ему готовить честный гроб И тихо целить бледный лоб На'\n",
            "\n",
            "Next Char Predictions: \n",
            " 'тщетный одарит чудное Несчастной разврата соседку заботной тишине шепнула надменный любимый Цель неподкупных патриотом смущал вкушает чистых мордой балы нахмуря Заглох Перо глубины Такие точны верна сохранила обновлю мод повод ум грусти взгляду вечное косу Свое Писать Хотя Обед Гарольдовом уроки румяных научена омуте ответ А Пастуший Отвсюду Подходит Красами наедине степей расстоянье вслед пламенных откуда Марает навылет ветреная Цимлянское охладелый исправляется кабинете Проласов Толстого переулке любил молвит лучами Пускается голубка Мосты проснулся Поймал столпы приезжать встретя свободного обновила невинный нагревая самое Уверен смену Ревнивой замечаньем вольностью тревога кольнем Поутру няня боялась Подагру неизвестный оживляй поражен Часы прочь летних приемный общую нежной судьбой Летит демоном Отвсюду маков Нейду Прослыть уроки хладнокровно волнуется Обнявшись Что заветных волнуемой привычная долинах союза XLII Татьяна Слегка Приятно отрок прихоти Позвольте лепетанья мать шутку девиц Младое Племен кажут Забыт цену грядущий забыла Забытый счастье весела глубокое Ведь поклоны забыла Мальчишки жеребца широкою сходит лесов Одна Зацепит веселье неге Плененный равнодушных мелким Ленский сенокосе трунил Трудов жалостный золота новым каком Киприды чахотке Хозяйки овладело Осталася долина готовым Неужто дочек острые кум сокрылась ручеек Мод сестрицам скатертью Поглотит раза засмоленной боярский брегам недвижим подавленным важной положила Ниной знала эпиграмм кареты Поставил Гиббона Виргилий боярский Задумав Грандисон горою'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# функция потерь\n",
        "\n",
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "# подсчитаем ошибку\n",
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd-CIe1Esz3O",
        "outputId": "e1f2e61b-8c7f-45f5-80be-72a7b5df53c2"
      },
      "execution_count": 496,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (16, 200, 8911)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       9.095045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение модели"
      ],
      "metadata": {
        "id": "tYo5YF5Ls0Yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# место для хранения checkpoint\n",
        "checkpoint_dir = '/content/training_checkpoints'\n",
        "# Имя файла checkpoint\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_freq=9*30, # сохраняем каждую 30-ю итерацию - в эпохе 44 батча (это видно при запуске обучения)\n",
        "    save_weights_only=True, # будем сохранять только веса\n",
        "    )"
      ],
      "metadata": {
        "id": "DGFXAo7Wsz1d"
      },
      "execution_count": 497,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Компиляция модели\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "pusf_JlltceU"
      },
      "execution_count": 498,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#обучение модели\n",
        "EPOCHS = 60\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_7ZylFUszzS",
        "outputId": "ed3ff56e-24d6-4398-e8b3-0fa2446b3fb8"
      },
      "execution_count": 499,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "5/5 [==============================] - 8s 311ms/step - loss: 8.9931\n",
            "Epoch 2/60\n",
            "5/5 [==============================] - 2s 304ms/step - loss: 8.6836\n",
            "Epoch 3/60\n",
            "5/5 [==============================] - 2s 305ms/step - loss: 8.4803\n",
            "Epoch 4/60\n",
            "5/5 [==============================] - 2s 306ms/step - loss: 8.4106\n",
            "Epoch 5/60\n",
            "5/5 [==============================] - 2s 307ms/step - loss: 8.3915\n",
            "Epoch 6/60\n",
            "5/5 [==============================] - 2s 306ms/step - loss: 8.3877\n",
            "Epoch 7/60\n",
            "5/5 [==============================] - 2s 312ms/step - loss: 8.3774\n",
            "Epoch 8/60\n",
            "5/5 [==============================] - 2s 306ms/step - loss: 8.3822\n",
            "Epoch 9/60\n",
            "5/5 [==============================] - 2s 303ms/step - loss: 8.3687\n",
            "Epoch 10/60\n",
            "5/5 [==============================] - 2s 304ms/step - loss: 8.3759\n",
            "Epoch 11/60\n",
            "5/5 [==============================] - 2s 302ms/step - loss: 8.3687\n",
            "Epoch 12/60\n",
            "5/5 [==============================] - 2s 305ms/step - loss: 8.3636\n",
            "Epoch 13/60\n",
            "5/5 [==============================] - 2s 304ms/step - loss: 8.3719\n",
            "Epoch 14/60\n",
            "5/5 [==============================] - 2s 304ms/step - loss: 8.3562\n",
            "Epoch 15/60\n",
            "5/5 [==============================] - 2s 304ms/step - loss: 8.3733\n",
            "Epoch 16/60\n",
            "5/5 [==============================] - 2s 304ms/step - loss: 8.3678\n",
            "Epoch 17/60\n",
            "5/5 [==============================] - 2s 307ms/step - loss: 8.3561\n",
            "Epoch 18/60\n",
            "5/5 [==============================] - 2s 306ms/step - loss: 8.3654\n",
            "Epoch 19/60\n",
            "5/5 [==============================] - 2s 305ms/step - loss: 8.3613\n",
            "Epoch 20/60\n",
            "5/5 [==============================] - 2s 307ms/step - loss: 8.3590\n",
            "Epoch 21/60\n",
            "5/5 [==============================] - 2s 307ms/step - loss: 8.3745\n",
            "Epoch 22/60\n",
            "5/5 [==============================] - 2s 308ms/step - loss: 8.3668\n",
            "Epoch 23/60\n",
            "5/5 [==============================] - 2s 307ms/step - loss: 8.3596\n",
            "Epoch 24/60\n",
            "5/5 [==============================] - 2s 307ms/step - loss: 8.3710\n",
            "Epoch 25/60\n",
            "5/5 [==============================] - 2s 308ms/step - loss: 8.3702\n",
            "Epoch 26/60\n",
            "5/5 [==============================] - 2s 309ms/step - loss: 8.3688\n",
            "Epoch 27/60\n",
            "5/5 [==============================] - 2s 310ms/step - loss: 8.3631\n",
            "Epoch 28/60\n",
            "5/5 [==============================] - 2s 309ms/step - loss: 8.3673\n",
            "Epoch 29/60\n",
            "5/5 [==============================] - 2s 310ms/step - loss: 8.3620\n",
            "Epoch 30/60\n",
            "5/5 [==============================] - 2s 309ms/step - loss: 8.3632\n",
            "Epoch 31/60\n",
            "5/5 [==============================] - 2s 313ms/step - loss: 8.3561\n",
            "Epoch 32/60\n",
            "5/5 [==============================] - 2s 312ms/step - loss: 8.3665\n",
            "Epoch 33/60\n",
            "5/5 [==============================] - 2s 310ms/step - loss: 8.3709\n",
            "Epoch 34/60\n",
            "5/5 [==============================] - 2s 310ms/step - loss: 8.3611\n",
            "Epoch 35/60\n",
            "5/5 [==============================] - 2s 311ms/step - loss: 8.3658\n",
            "Epoch 36/60\n",
            "5/5 [==============================] - 2s 312ms/step - loss: 8.3603\n",
            "Epoch 37/60\n",
            "5/5 [==============================] - 2s 313ms/step - loss: 8.3675\n",
            "Epoch 38/60\n",
            "5/5 [==============================] - 2s 313ms/step - loss: 8.3642\n",
            "Epoch 39/60\n",
            "5/5 [==============================] - 2s 313ms/step - loss: 8.3554\n",
            "Epoch 40/60\n",
            "5/5 [==============================] - 2s 311ms/step - loss: 8.3565\n",
            "Epoch 41/60\n",
            "5/5 [==============================] - 2s 312ms/step - loss: 8.3688\n",
            "Epoch 42/60\n",
            "5/5 [==============================] - 2s 314ms/step - loss: 8.3608\n",
            "Epoch 43/60\n",
            "5/5 [==============================] - 2s 312ms/step - loss: 8.3532\n",
            "Epoch 44/60\n",
            "5/5 [==============================] - 2s 312ms/step - loss: 8.3561\n",
            "Epoch 45/60\n",
            "5/5 [==============================] - 2s 314ms/step - loss: 8.3534\n",
            "Epoch 46/60\n",
            "5/5 [==============================] - 2s 314ms/step - loss: 8.3625\n",
            "Epoch 47/60\n",
            "5/5 [==============================] - 2s 314ms/step - loss: 8.3629\n",
            "Epoch 48/60\n",
            "5/5 [==============================] - 2s 315ms/step - loss: 8.3609\n",
            "Epoch 49/60\n",
            "5/5 [==============================] - 2s 315ms/step - loss: 8.3588\n",
            "Epoch 50/60\n",
            "5/5 [==============================] - 2s 313ms/step - loss: 8.3620\n",
            "Epoch 51/60\n",
            "5/5 [==============================] - 2s 314ms/step - loss: 8.3576\n",
            "Epoch 52/60\n",
            "5/5 [==============================] - 2s 319ms/step - loss: 8.3563\n",
            "Epoch 53/60\n",
            "5/5 [==============================] - 2s 322ms/step - loss: 8.3605\n",
            "Epoch 54/60\n",
            "5/5 [==============================] - 3s 751ms/step - loss: 8.3558\n",
            "Epoch 55/60\n",
            "5/5 [==============================] - 2s 315ms/step - loss: 8.3563\n",
            "Epoch 56/60\n",
            "5/5 [==============================] - 2s 316ms/step - loss: 8.3642\n",
            "Epoch 57/60\n",
            "5/5 [==============================] - 2s 316ms/step - loss: 8.3545\n",
            "Epoch 58/60\n",
            "5/5 [==============================] - 2s 317ms/step - loss: 8.3552\n",
            "Epoch 59/60\n",
            "5/5 [==============================] - 2s 316ms/step - loss: 8.3541\n",
            "Epoch 60/60\n",
            "5/5 [==============================] - 2s 316ms/step - loss: 8.3623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#предсказание модели\n",
        "example_batch_predictions = model(input_example_batch)\n",
        "print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "id": "dl6Wg-oTszuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "813be7ca-cf65-4479-a03f-d43e401b7d92"
      },
      "execution_count": 500,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16, 200, 8911) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "metadata": {
        "id": "qjKgRJmP5A83"
      },
      "execution_count": 501,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2token[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2token[sampled_indices ])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V4YCOCU5Cj1",
        "outputId": "df2b68e7-2ab3-4a92-bcc7-753ae19607e6"
      },
      "execution_count": 502,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: \n",
            " 'пеньСтановитсяГильосмущенныйПлащибросаютврагаЗарецкийтридцатьшагаОтмерилточностьюотменнойДрузейразвелкрайнийследИвзялсвойпистолетXXXТеперьсходитесьХладнокровноЕщецеляврагаПоходкойтвердойтихоровноЧетыреперешлишагаЧетыресмертныеступениСвойпистолетЕвгенийНепреставаянаступатьСталтихоподыматьВотшаговступилиИЛенскийжмурялевыйглазСталцелитьОнегинвыстрелилПробилиЧасыурочныепоэтРоняетмолчапистолетXXXIНагрудькладеттихонькорукуИпадаетТуманныйвзорИзображаетсмертьмукуТакмедленноскатугорНасолнцеискрамиблистаяСпадаетглыбаснеговаяМгновеннымхолодомоблитОнегинюношеспешитГлядитзоветнапрасноЕгоМладойпевецНашелбезвременныйконецДохнулабуряцветпрекрасныйУвялутреннейзареПотухогоньалтареXXXIIНедвижимлежалстраненБылтомныймирчелаПодгрудьнавылетраненДымясьраныкровьтеклаТомуодномгновеньеВсемсердцебилосьвдохновеньеВражданадеждалюбовьИгралакипелакровьТеперьдомеопустеломВсетихотемноЗамолклонавсегдаЗакрытыставниокнымеломЗабеленыХозяйкиАбогвестьПропалследXXXIIIПриятнодерзкойэпиграммойВзбеситьоплошноговрагаПриятнозретьупрямоСклонивбодливыерогаНевольнозеркалоглядитсяИузнаватьстыдитсяПриятнейдрузьяЗавоетсдуруЕщеприятнеемолчаньеЕмуготовитьчестныйгробИтихоцелитьбледныйлобНа'\n",
            "\n",
            "Next Char Predictions: \n",
            " 'ТупымпеременыпокойнаКаквздоховТатьянаневинныйсвежийВсепервыххвалитьВзлодействадомничтоМнеШумитбaдокучныхСклониввзялснегомдокучалВиздалекальЗарябродягаблагословилАрмидОнегинсделайУдивленароманногидниДобитьсяПрощайстихизнаешьголосполупечальныхВзбеситьМнеИхорслезыжестокомИИкочующийглухойкнягинейречейДамскихЯсветеПорасупругомпасмурнымТомуслугаминочейАВшипитвведуткипитльвыплаткоммирныхмолодойраненвечнопоединкомСпросилаизголовьюзалуСебеВолнуйпоправянаперсницасветастволлессходиттазыИслушалаСвиданьяЛенскийИпедантИговорятравнодушноюСенекалужокДниДостойнаНаНаполеонМаратьвьетсяОтецНедавнеюТатьянойталиикреслаВступилирисуетКигралалюбовьюзвучнотоварищейпредметыЕдваЧиталСнаводитсвободуСперомужОблаткаНепостижимыхХотьмоейсоглашалсяСпалстыдитсянаводилиПартерСолилаЧтобСДругоюДверьпамятибурноймостикиУпрямоУслужливомыслейзабывшисьДеревняпроходитСамНалевоСогретойкакиеТатьянарассеяньедругузоромвздыхалаподастотплатуПриятноЕвгенийсмотритИвиназатихдушеМельмотисключилумиленьяполкуКоторойУверентотчасРодныеподыматьУвидяладониИЗатоУвысадПетушковискалплакалаБледнадерзкойнамараллежалсветеУжЕвгенийгорестнойпокоепистолетречказамениликольнемдубравывешними'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Генерация текста"
      ],
      "metadata": {
        "id": "uhJEUtw51sVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Находим имя файла последней сохраненной контрольной точки\n",
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "9sa4y2eJ5Ipr",
        "outputId": "81694a1a-6861-4fd9-d2ab-1c1baf28da7a"
      },
      "execution_count": 503,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/training_checkpoints/ckpt_54'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 503
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#строим модель\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "#загружаем веса из последней сохраненной контрольной точки в модель\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "metadata": {
        "id": "lUYLFUii5Im4"
      },
      "execution_count": 504,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#информация о модели\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh_-r2yq5IhJ",
        "outputId": "083a813f-9e5d-4d7d-9079-fa820d22f775"
      },
      "execution_count": 505,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_13 (Embedding)    (1, None, 512)            4562432   \n",
            "                                                                 \n",
            " lstm_51 (LSTM)              (1, None, 1024)           6295552   \n",
            "                                                                 \n",
            " lstm_52 (LSTM)              (1, None, 1024)           8392704   \n",
            "                                                                 \n",
            " lstm_53 (LSTM)              (1, None, 1024)           8392704   \n",
            "                                                                 \n",
            " lstm_54 (LSTM)              (1, None, 1024)           8392704   \n",
            "                                                                 \n",
            " dense_13 (Dense)            (1, None, 8911)           9133775   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45,169,871\n",
            "Trainable params: 45,169,871\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string):\n",
        "    # Этап оценки (генерация текста с использованием обученной модели)\n",
        "\n",
        "    # число токенов для генераци\n",
        "    num_generate = 10\n",
        "\n",
        "    # Преобразование начальной строки в числа (векторизация)\n",
        "    input_eval = [token2idx[s] for s in make_tokens(start_string)]\n",
        "    #Возвращаем тензор с осью длины 1, вставленной первой в индекс\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "    # print(input_eval)\n",
        "\n",
        "    # Пустая строка для хранения результатов\n",
        "    text_generated = []\n",
        "\n",
        "    # Низкая температура приводит к более предсказуемому тексту.\n",
        "    # Более высокая температура приводит к более неожиданному тексту.\n",
        "    temperature = 0.5\n",
        "\n",
        "    # здесь batch size == 1\n",
        "    # сбрасываем состояния всех слоев в модели\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "\n",
        "        #получаем предсказания модели\n",
        "        predictions = model(input_eval)\n",
        "\n",
        "        #удаляем первую размерность в предсказании\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        # использование категориального распределения для прогнозирования символа, возвращаемого моделью\n",
        "        # predictions = predictions / temperature\n",
        "\n",
        "        # выберем последний токен из отсэмплированных предсказаний[-1], т.к. именно он будет предсказанным следующим токеном в строке\n",
        "        # индекс 0 - выбираем именно индекс токена (помимо него выводится еще размер [1]и тип [2])\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "        # print(predicted_id)\n",
        "\n",
        "        # Передаем предсказанный символ в качестве следующего ввода в модель, по нему будет предсказывать следующий символ\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        #сохраняем предсказанную букву\n",
        "        text_generated.append(idx2token[predicted_id])\n",
        "\n",
        "    return (start_string + ' '.join(text_generated))\n",
        "        "
      ],
      "metadata": {
        "id": "13GNNQ8T5Iew"
      },
      "execution_count": 523,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_ = generate_text(model, start_string=u\"Вот он идет \")\n",
        "print(text_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyD6oHGVAy3i",
        "outputId": "1463c67b-8803-4c6c-bf04-2dd2e29eea15"
      },
      "execution_count": 524,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вот он идет Довольно Отец Его Татьяна пробужден лежит Евгений представить благословил холодный\n"
          ]
        }
      ]
    }
  ]
}